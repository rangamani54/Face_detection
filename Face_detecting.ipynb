{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the required photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected required images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as mpl\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "model = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    ret, photo = cap.read()\n",
    "    faces = model.detectMultiScale(photo)\n",
    "    if len(faces) is None:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    elif len(faces) is not None:\n",
    "        count +=1\n",
    "        x1 = faces[0][0]\n",
    "        y1 = faces[0][1]\n",
    "        x2 = x1 + faces[0][2]\n",
    "        y2 = y1 + faces[0][3]\n",
    "        \n",
    "        #photor =  cv2.rectangle(photo, (x1,y1), (x2,y2), [0,255,0], 5)\n",
    "        gray_photo = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)\n",
    "        cropped_photo = gray_photo[y1:y2, x1:x2]\n",
    "        photor = cv2.resize(cropped_photo, (200,200))\n",
    "        file_path = \"./photos/\"+ str(count)+\"new.jpg\"\n",
    "        cv2.imwrite(file_path,photor)\n",
    "        cv2.putText(photor, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow(\"photo\", photor)\n",
    "        if cv2.waitKey(1) ==13 or count==100:\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print(\"Collected required images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model from above collected photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessfully\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = \"./photos/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "Ranga_Mani_model = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "Ranga_Mani_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessfully\")\n",
    "Ranga_Mani_model.save(\"rangamanimodel.h5\")\n",
    "print(\"Model saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating mail function for sending mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail():\n",
    "    import smtplib\n",
    "    import os\n",
    "    from email.message import EmailMessage\n",
    "    msg = EmailMessage()\n",
    "    user = %env USER\n",
    "    password = %env PASSWD\n",
    "    mailr = \"ranga.mani54@gmail.com\"\n",
    "    msg.set_content(\"Hello Your face is recognised\")\n",
    "    msg[\"subject\"] = \"Face Recognition\"\n",
    "    msg[\"to\"] = \"ranga.mani54@gmail.com\"\n",
    "    msg[\"from\"] = user\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "    server.starttls()\n",
    "    server.login(user, password)\n",
    "    server.send_message(msg)\n",
    "    print(\"Email sent successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what():\n",
    "    # importing the module\n",
    "    import pywhatkit\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    m = int(now.strftime(\"%M\"))\n",
    "    hr = int(now.strftime(\"%H\"))\n",
    "\n",
    "    # using Exception Handling to avoid\n",
    "    # unprecedented errors\n",
    "    try:\n",
    "\n",
    "        # sending message to reciever\n",
    "        # using pywhatkit\n",
    "        number = %env NUMBER\n",
    "        pywhatkit.sendwhatmsg(number,\"Hello, face is recognised\",hr, m+1, wait_time=30)\n",
    "        print(\"Successfully Sent!\")\n",
    "\n",
    "    except:\n",
    "\n",
    "        # handling exception\n",
    "        # and printing error message\n",
    "        print(\"An Unexpected Error!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the face and sending mail and whatsapp message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-78-c4ae867ff777>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 19 seconds web.whatsapp.com will open and after 30 seconds message will be delivered\n",
      "Email sent successfully\n",
      "Successfully Sent!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        model = cv2.face_LBPHFaceRecognizer.create()\n",
    "        model.read(\"rangamanimodel.h5\")\n",
    "        results = model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 80:\n",
    "            cv2.putText(image, \"Hey Ranga Mani\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            t1 = threading.Thread(target=mail)\n",
    "            t2 = threading.Thread(target = what)\n",
    "            t1.start()\n",
    "            t2.start()\n",
    "            break\n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, who r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting friend's photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret, photo = cap.read()\n",
    "    model = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = model.detectMultiScale(photo)\n",
    "    if len(faces) is None:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    elif len(faces) is not None:\n",
    "        count +=1\n",
    "        x1 = faces[0][0]\n",
    "        y1 = faces[0][1]\n",
    "        x2 = x1 + faces[0][2]\n",
    "        y2 = y1 + faces[0][3]\n",
    "        \n",
    "        #photor =  cv2.rectangle(photo, (x1,y1), (x2,y2), [0,255,0], 5)\n",
    "        gray_photo = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)\n",
    "        cropped_photo = gray_photo[y1:y2, x1:x2]\n",
    "        photor = cv2.resize(cropped_photo, (200,200))\n",
    "        file_path = \"./photos/friend/\"+ str(count)+\".jpg\"\n",
    "        cv2.imwrite(file_path,photor)\n",
    "        cv2.putText(photor, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow(\"photo\", photor)\n",
    "        if cv2.waitKey(1) ==13 or count==100:\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print(\"Collected required images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model for friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessfully\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = \"./photos/friend/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "friend_model = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "friend_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessfully\")\n",
    "friend_model.save(\"friend.h5\")\n",
    "print(\"Model saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Launching Instance, Volume and Attaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(cmd):\n",
    "    from subprocess import getstatusoutput\n",
    "    global akey\n",
    "    akey = getstatusoutput(cmd)\n",
    "    if akey[0] == 0:\n",
    "        print(\"Here is the output you are looking for\")\n",
    "        print(akey[1])\n",
    "    else: \n",
    "        print(\"Error occured : {}\".format(akey[1]))\n",
    "    \n",
    "            \n",
    "\n",
    "# To launch Instance in AWS\n",
    "def aws_linstances(instance_type,instance_number,sg_id,key_name,name):\n",
    "    output(\"aws ec2 run-instances --image-id ami-0e306788ff2473ccb --instance-type {0} --count {1} --subnet-id subnet-c40108ac --security-group-ids {3} --key-name {2} --tag-specifications ResourceType=instance,Tags=[{{Key=Name,Value={4}}}]\".format(\n",
    "\t\tinstance_type,instance_number,key_name,sg_id,name))\n",
    "    \n",
    "            \n",
    "\n",
    "# To create EBS Volume\n",
    "def aws_cvol(size,name):\n",
    "    output(\"aws ec2 create-volume --availability-zone ap-south-1a --volume-type gp2 --size {0} --tag-specifications ResourceType=volume,Tags=[{{Key=Name,Value={1}}}]\".format(size,name))\n",
    "    \n",
    "            \n",
    "# To Attach EBS Volume\n",
    "def aws_avol(instance_id,vol_id):\n",
    "    output(\"aws ec2 attach-volume --volume-id {0} --instance-id {1} --device /dev/sdf\".format(vol_id,instance_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the friend's face and doing the required action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-88-b8c658816328>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output you are looking for\n",
      "{\n",
      "    \"AvailabilityZone\": \"ap-south-1a\",\n",
      "    \"CreateTime\": \"2021-06-24T17:57:17+00:00\",\n",
      "    \"Encrypted\": false,\n",
      "    \"Size\": 3,\n",
      "    \"SnapshotId\": \"\",\n",
      "    \"State\": \"creating\",\n",
      "    \"VolumeId\": \"vol-0bd15a1d6ace415a0\",\n",
      "    \"Iops\": 100,\n",
      "    \"Tags\": [\n",
      "        {\n",
      "            \"Key\": \"Name\",\n",
      "            \"Value\": \"testing\"\n",
      "        }\n",
      "    ],\n",
      "    \"VolumeType\": \"gp2\",\n",
      "    \"MultiAttachEnabled\": false\n",
      "}\n",
      "Here is the output you are looking for\n",
      "{\n",
      "    \"Groups\": [],\n",
      "    \"Instances\": [\n",
      "        {\n",
      "            \"AmiLaunchIndex\": 0,\n",
      "            \"ImageId\": \"ami-0e306788ff2473ccb\",\n",
      "            \"InstanceId\": \"i-0bb062a837ee09d06\",\n",
      "            \"InstanceType\": \"t2.micro\",\n",
      "            \"KeyName\": \"hadoopkey\",\n",
      "            \"LaunchTime\": \"2021-06-24T17:57:17+00:00\",\n",
      "            \"Monitoring\": {\n",
      "                \"State\": \"disabled\"\n",
      "            },\n",
      "            \"Placement\": {\n",
      "                \"AvailabilityZone\": \"ap-south-1a\",\n",
      "                \"GroupName\": \"\",\n",
      "                \"Tenancy\": \"default\"\n",
      "            },\n",
      "            \"PrivateDnsName\": \"ip-172-31-46-252.ap-south-1.compute.internal\",\n",
      "            \"PrivateIpAddress\": \"172.31.46.252\",\n",
      "            \"ProductCodes\": [],\n",
      "            \"PublicDnsName\": \"\",\n",
      "            \"State\": {\n",
      "                \"Code\": 0,\n",
      "                \"Name\": \"pending\"\n",
      "            },\n",
      "            \"StateTransitionReason\": \"\",\n",
      "            \"SubnetId\": \"subnet-c40108ac\",\n",
      "            \"VpcId\": \"vpc-a9d232c2\",\n",
      "            \"Architecture\": \"x86_64\",\n",
      "            \"BlockDeviceMappings\": [],\n",
      "            \"ClientToken\": \"6fbfd830-f90d-4a37-902a-d83bc66f27e2\",\n",
      "            \"EbsOptimized\": false,\n",
      "            \"EnaSupport\": true,\n",
      "            \"Hypervisor\": \"xen\",\n",
      "            \"NetworkInterfaces\": [\n",
      "                {\n",
      "                    \"Attachment\": {\n",
      "                        \"AttachTime\": \"2021-06-24T17:57:17+00:00\",\n",
      "                        \"AttachmentId\": \"eni-attach-0eb918c1bd4e60f51\",\n",
      "                        \"DeleteOnTermination\": true,\n",
      "                        \"DeviceIndex\": 0,\n",
      "                        \"Status\": \"attaching\"\n",
      "                    },\n",
      "                    \"Description\": \"\",\n",
      "                    \"Groups\": [\n",
      "                        {\n",
      "                            \"GroupName\": \"webserver\",\n",
      "                            \"GroupId\": \"sg-0f2a5a273a2a190ec\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"Ipv6Addresses\": [],\n",
      "                    \"MacAddress\": \"02:d6:c9:10:26:66\",\n",
      "                    \"NetworkInterfaceId\": \"eni-0a45934db9b617eb6\",\n",
      "                    \"OwnerId\": \"311010486343\",\n",
      "                    \"PrivateDnsName\": \"ip-172-31-46-252.ap-south-1.compute.internal\",\n",
      "                    \"PrivateIpAddress\": \"172.31.46.252\",\n",
      "                    \"PrivateIpAddresses\": [\n",
      "                        {\n",
      "                            \"Primary\": true,\n",
      "                            \"PrivateDnsName\": \"ip-172-31-46-252.ap-south-1.compute.internal\",\n",
      "                            \"PrivateIpAddress\": \"172.31.46.252\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"SourceDestCheck\": true,\n",
      "                    \"Status\": \"in-use\",\n",
      "                    \"SubnetId\": \"subnet-c40108ac\",\n",
      "                    \"VpcId\": \"vpc-a9d232c2\",\n",
      "                    \"InterfaceType\": \"interface\"\n",
      "                }\n",
      "            ],\n",
      "            \"RootDeviceName\": \"/dev/xvda\",\n",
      "            \"RootDeviceType\": \"ebs\",\n",
      "            \"SecurityGroups\": [\n",
      "                {\n",
      "                    \"GroupName\": \"webserver\",\n",
      "                    \"GroupId\": \"sg-0f2a5a273a2a190ec\"\n",
      "                }\n",
      "            ],\n",
      "            \"SourceDestCheck\": true,\n",
      "            \"StateReason\": {\n",
      "                \"Code\": \"pending\",\n",
      "                \"Message\": \"pending\"\n",
      "            },\n",
      "            \"Tags\": [\n",
      "                {\n",
      "                    \"Key\": \"Name\",\n",
      "                    \"Value\": \"testing\"\n",
      "                }\n",
      "            ],\n",
      "            \"VirtualizationType\": \"hvm\",\n",
      "            \"CpuOptions\": {\n",
      "                \"CoreCount\": 1,\n",
      "                \"ThreadsPerCore\": 1\n",
      "            },\n",
      "            \"CapacityReservationSpecification\": {\n",
      "                \"CapacityReservationPreference\": \"open\"\n",
      "            },\n",
      "            \"MetadataOptions\": {\n",
      "                \"State\": \"pending\",\n",
      "                \"HttpTokens\": \"optional\",\n",
      "                \"HttpPutResponseHopLimit\": 1,\n",
      "                \"HttpEndpoint\": \"enabled\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"OwnerId\": \"311010486343\",\n",
      "    \"ReservationId\": \"r-04d0665179ec2e1d1\"\n",
      "}\n",
      "Enter Instance ID: i-0bb062a837ee09d06\n",
      "Enter Volume ID: vol-0bd15a1d6ace415a0\n",
      "Here is the output you are looking for\n",
      "{\n",
      "    \"AttachTime\": \"2021-06-24T17:59:00.185000+00:00\",\n",
      "    \"Device\": \"/dev/sdf\",\n",
      "    \"InstanceId\": \"i-0bb062a837ee09d06\",\n",
      "    \"State\": \"attaching\",\n",
      "    \"VolumeId\": \"vol-0bd15a1d6ace415a0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        model = cv2.face_LBPHFaceRecognizer.create()\n",
    "        model.read(\"friend.h5\")\n",
    "        results = model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 80:\n",
    "            cv2.putText(image, \"Hey friend\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            t1 = threading.Thread(target=aws_linstances, args=(\"t2.micro\", 1,\"sg-0f2a5a273a2a190ec\", \"hadoopkey\", \"testing\"))\n",
    "            t2 = threading.Thread(target = aws_cvol, args=(3,\"testing\"))\n",
    "            t1.start()\n",
    "            t2.start()\n",
    "            inst_id = input(\"Enter Instance ID: \")\n",
    "            vol_id = input(\"Enter Volume ID: \")\n",
    "            aws_avol(inst_id, vol_id)\n",
    "            break\n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, who r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(10) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
